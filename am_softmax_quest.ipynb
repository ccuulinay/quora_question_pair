{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clusters_train_file = \"./data/stacked_clusters_train_df.csv\"\n",
    "stacked_clusters_train_df = pd.read_csv(stacked_clusters_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_class</th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_class  qid                                           question\n",
       "0        0   11  Astrology: I am a Capricorn Sun Cap moon and c...\n",
       "1        0   12  I'm a triple Capricorn (Sun, Moon and ascendan...\n",
       "2        1   16          What should I do to be a great geologist?\n",
       "3        1   15                     How can I be a good geologist?\n",
       "4        2   24             How can I see all my Youtube comments?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_clusters_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = stacked_clusters_train_df[['q_class', 'question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_class</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_class                                           question\n",
       "0        0  Astrology: I am a Capricorn Sun Cap moon and c...\n",
       "1        0  I'm a triple Capricorn (Sun, Moon and ascendan...\n",
       "2        1          What should I do to be a great geologist?\n",
       "3        1                     How can I be a good geologist?\n",
       "4        2             How can I see all my Youtube comments?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149650 entries, 0 to 149649\n",
      "Data columns (total 2 columns):\n",
      "q_class     149650 non-null int64\n",
      "question    149650 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "Total question classes: 60460\n"
     ]
    }
   ],
   "source": [
    "print(data_df.info())\n",
    "print(\"Total question classes: {}\".format(data_df.q_class.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maxlen = 64\n",
    "batch_size = 128\n",
    "epochs = 25 # amsoftmax需要25个epoch，其它需要20个epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_groups = int(np.floor(data_df.q_class.unique().shape[0] * 0.8)) #\n",
    "\n",
    "train_data = data_df[data_df.q_class <= num_train_groups].copy()\n",
    "valid_data = data_df[data_df.q_class > num_train_groups].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125243, 2)\n",
      "(24407, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy\n",
    "# !conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "# nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(vocab):\n",
    "    return vocab.vectors.data\n",
    "\n",
    "def get_embeddings_loop(vocab):\n",
    "    max_rank = max(lex.rank for lex in vocab if lex.has_vector)\n",
    "    vectors = np.ndarray((max_rank+1, vocab.vectors_length), dtype='float32')\n",
    "    for lex in vocab:\n",
    "        if lex.has_vector:\n",
    "            vectors[lex.rank] = lex.vector\n",
    "    return vectors\n",
    "\n",
    "def get_features_from_list_docs(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            # Get the vector id from the vocab of embeddings.\n",
    "            # token.orth return total vector id.\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs\n",
    "# Testing\n",
    "# np.shape(get_features_from_list_docs(nlp.pipe(x_data[:2]), maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_embeddings = get_embeddings(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(spacy_embeddings.shape)\n",
    "# print(spacy_embeddings_loop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = get_features_from_list_docs(nlp.pipe(train_data.question.values), maxlen)\n",
    "y_train_data = train_data.q_class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_data = get_features_from_list_docs(nlp.pipe(valid_data.question.values), maxlen)\n",
    "y_valid_data = valid_data.q_class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data = y_train_data.reshape((-1,1))\n",
    "y_valid_data = y_valid_data.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import K\n",
    "from keras.layers import LSTM, CuDNNGRU, GRU\n",
    "from keras.layers import Lambda\n",
    "from keras.constraints import unit_norm\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.utils import np_utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from margin_softmax import sparse_amsoftmax_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model_25epoch.h5')\n",
    "encoder = load_model('encoder_25epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正式模型，基于GRU的分类器\n",
    "x_in = Input(shape=(maxlen,))\n",
    "x_embedded = Embedding(\n",
    "        spacy_embeddings.shape[0],\n",
    "        spacy_embeddings.shape[1],\n",
    "        input_length=maxlen,\n",
    "        trainable=False,\n",
    "        weights=[spacy_embeddings])(x_in)\n",
    "x = CuDNNGRU(spacy_embeddings.shape[1])(x_embedded)\n",
    "# x = GRU(spacy_embeddings.shape[1])(x_embedded)\n",
    "x = Lambda(lambda x: K.l2_normalize(x, 1))(x)\n",
    "\n",
    "pred = Dense(num_train_groups,\n",
    "             use_bias=False,\n",
    "             kernel_constraint=unit_norm())(x)\n",
    "\n",
    "encoder = Model(x_in, x) # 最终的目的是要得到一个编码器\n",
    "model = Model(x_in, pred) # 用分类问题做训练\n",
    "\n",
    "model.compile(loss=sparse_amsoftmax_loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为验证集的排序准备\n",
    "# 实际上用numpy写也没有问题，但是用Keras写能借助GPU加速\n",
    "x_in = Input(shape=(spacy_embeddings.shape[1],))\n",
    "x = Dense(len(valid_data), use_bias=False)(x_in) # 计算相似度\n",
    "x = Lambda(lambda x: K.tf.nn.top_k(x, 11)[1])(x) # 取出topk的下标\n",
    "model_sort = Model(x_in, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2g = dict(zip(valid_data.index-valid_data.index[0], valid_data.q_class))\n",
    "\n",
    "def evaluate(): # 评测函数\n",
    "    print('validing...')\n",
    "    valid_vec = encoder.predict(\n",
    "        # np.array(list(x_valid_data)),\n",
    "        x_valid_data,\n",
    "                                verbose=True,\n",
    "                                batch_size=1000) # encoder计算句向量\n",
    "    model_sort.set_weights([valid_vec.T]) # 载入句向量为权重\n",
    "    sorted_result = model_sort.predict(valid_vec,\n",
    "                                       verbose=True,\n",
    "                                       batch_size=1000) # 计算topk\n",
    "    new_result = np.vectorize(lambda s: id2g[s])(sorted_result)\n",
    "    _ = new_result[:, 0] != new_result[:, 0] # 生成一个全为False的向量\n",
    "    for i in range(10): # 注意按照相似度排序的话，第一个就是输入句子（全匹配）\n",
    "        _ = _ + (new_result[:, 0] == new_result[:, i+1])\n",
    "        if i+1 == 1:\n",
    "            top1_acc = 1. * _.sum() / len(_)\n",
    "        elif i+1 == 5:\n",
    "            top5_acc = 1. * _.sum() / len(_)\n",
    "        elif i+1 == 10:\n",
    "            top10_acc = 1. * _.sum() / len(_)\n",
    "\n",
    "    return top1_acc, top5_acc, top10_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Callback器，计算验证集的acc，并保存最优模型\n",
    "class Evaluate(Callback):\n",
    "    def __init__(self):\n",
    "        self.accs = {'top1': [], 'top5': [], 'top10': []}\n",
    "        self.highest = 0.\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        top1_acc, top5_acc, top10_acc = evaluate()\n",
    "        self.accs['top1'].append(top1_acc)\n",
    "        self.accs['top5'].append(top5_acc)\n",
    "        self.accs['top10'].append(top10_acc)\n",
    "        if top1_acc >= self.highest: # 保存最优模型权重\n",
    "            self.highest = top1_acc\n",
    "            model.save_weights('sent_sim_amsoftmax.model')\n",
    "        json.dump({'accs': self.accs, 'highest_top1': self.highest},\n",
    "                  open('valid_amsoftmax.log', 'w'), indent=4)\n",
    "        print('top1_acc: %s, top5_acc: %s, top10_acc: %s' % (top1_acc, top5_acc, top10_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "125243/125243 [==============================] - 44s 354us/step - loss: 22.6312 - sparse_categorical_accuracy: 3.1938e-05\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 33us/step\n",
      "24407/24407 [==============================] - 0s 12us/step\n",
      "top1_acc: 0.03834965378784775, top5_acc: 0.05060023763674356, top10_acc: 0.055680747326586635\n",
      "Epoch 2/25\n",
      "125243/125243 [==============================] - 43s 345us/step - loss: 22.9227 - sparse_categorical_accuracy: 1.6767e-04\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 31us/step\n",
      "24407/24407 [==============================] - 0s 11us/step\n",
      "top1_acc: 0.1668373827180727, top5_acc: 0.2163723521940427, top10_acc: 0.23837423689925022\n",
      "Epoch 3/25\n",
      "125243/125243 [==============================] - 43s 347us/step - loss: 22.2273 - sparse_categorical_accuracy: 0.0014\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 34us/step\n",
      "24407/24407 [==============================] - 0s 12us/step\n",
      "top1_acc: 0.12365305035440652, top5_acc: 0.16925472200598188, top10_acc: 0.19326422747572417\n",
      "Epoch 4/25\n",
      "125243/125243 [==============================] - 44s 352us/step - loss: 20.0281 - sparse_categorical_accuracy: 0.0170\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 35us/step\n",
      "24407/24407 [==============================] - 0s 12us/step\n",
      "top1_acc: 0.46130208546728396, top5_acc: 0.5949522677920269, top10_acc: 0.648010816569017\n",
      "Epoch 5/25\n",
      "125243/125243 [==============================] - 44s 355us/step - loss: 15.6004 - sparse_categorical_accuracy: 0.2001\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.6504691277092637, top5_acc: 0.7816200270414225, top10_acc: 0.8250911623714509\n",
      "Epoch 6/25\n",
      "125243/125243 [==============================] - 45s 358us/step - loss: 11.9815 - sparse_categorical_accuracy: 0.5953\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.7313065923710411, top5_acc: 0.8481173433850945, top10_acc: 0.8812226000737493\n",
      "Epoch 7/25\n",
      "125243/125243 [==============================] - 45s 358us/step - loss: 9.1089 - sparse_categorical_accuracy: 0.8363\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.771786782480436, top5_acc: 0.8816323185971238, top10_acc: 0.9096160937435982\n",
      "Epoch 8/25\n",
      "125243/125243 [==============================] - 45s 358us/step - loss: 6.9420 - sparse_categorical_accuracy: 0.9150\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.7949768509034294, top5_acc: 0.8984307780554759, top10_acc: 0.9248576228131273\n",
      "Epoch 9/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 5.4441 - sparse_categorical_accuracy: 0.9441\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8100135207112713, top5_acc: 0.9084279100258122, top10_acc: 0.9321506125291924\n",
      "Epoch 10/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 4.4652 - sparse_categorical_accuracy: 0.9571\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8191502437825214, top5_acc: 0.9126889826689064, top10_acc: 0.9348957266358012\n",
      "Epoch 11/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 3.8237 - sparse_categorical_accuracy: 0.9657\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8206662023190069, top5_acc: 0.9140000819437046, top10_acc: 0.9364526570246241\n",
      "Epoch 12/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 3.3943 - sparse_categorical_accuracy: 0.9706\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8252140779284631, top5_acc: 0.917072970869013, top10_acc: 0.9375998688900725\n",
      "Epoch 13/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 3.0904 - sparse_categorical_accuracy: 0.9742\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8269348957266358, top5_acc: 0.917810464211087, top10_acc: 0.939115827426558\n",
      "Epoch 14/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 2.8618 - sparse_categorical_accuracy: 0.9768\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8285327979677961, top5_acc: 0.9198180849756218, top10_acc: 0.940508870406031\n",
      "Epoch 15/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 2.6818 - sparse_categorical_accuracy: 0.9792\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8318105461547917, top5_acc: 0.9199000286802966, top10_acc: 0.940140123734994\n",
      "Epoch 16/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 2.5372 - sparse_categorical_accuracy: 0.9806\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8325480394968656, top5_acc: 0.9204736346130209, top10_acc: 0.9414512230097922\n",
      "Epoch 17/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 2.4051 - sparse_categorical_accuracy: 0.9822\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.832670955053878, top5_acc: 0.921047240545745, top10_acc: 0.9421067726471913\n",
      "Epoch 18/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 2.2956 - sparse_categorical_accuracy: 0.9830\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8343508009997131, top5_acc: 0.9219486212971688, top10_acc: 0.9415331667144672\n",
      "Epoch 19/25\n",
      "125243/125243 [==============================] - 45s 359us/step - loss: 2.1943 - sparse_categorical_accuracy: 0.9843\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8340639980333511, top5_acc: 0.9205146064653583, top10_acc: 0.9410415044864179\n",
      "Epoch 20/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 2.1072 - sparse_categorical_accuracy: 0.9854\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8364813373212603, top5_acc: 0.9226041709345679, top10_acc: 0.9415741385668046\n",
      "Epoch 21/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 2.0340 - sparse_categorical_accuracy: 0.9863\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8353750973081493, top5_acc: 0.9223993116728807, top10_acc: 0.9416560822714795\n",
      "Epoch 22/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 1.9649 - sparse_categorical_accuracy: 0.9871\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8363174499119105, top5_acc: 0.922235424263531, top10_acc: 0.942352603761216\n",
      "Epoch 23/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 1.8900 - sparse_categorical_accuracy: 0.9877\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8364403654689229, top5_acc: 0.9226451427869053, top10_acc: 0.9431310689556275\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125243/125243 [==============================] - 45s 360us/step - loss: 1.8347 - sparse_categorical_accuracy: 0.9880\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 37us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.835989675093211, top5_acc: 0.9212930716597697, top10_acc: 0.9416560822714795\n",
      "Epoch 25/25\n",
      "125243/125243 [==============================] - 45s 360us/step - loss: 1.7721 - sparse_categorical_accuracy: 0.9888\n",
      "validing...\n",
      "24407/24407 [==============================] - 1s 36us/step\n",
      "24407/24407 [==============================] - 0s 13us/step\n",
      "top1_acc: 0.8376695210390461, top5_acc: 0.921047240545745, top10_acc: 0.941246363748105\n",
      "24407/24407 [==============================] - 1s 36us/step\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluate()\n",
    "\n",
    "history = model.fit(x_train_data,\n",
    "                    y_train_data,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[evaluator])\n",
    "\n",
    "\n",
    "valid_vec = encoder.predict(x_valid_data,\n",
    "                            verbose=True,\n",
    "                            batch_size=1000) # encoder计算句向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_25epoch.h5')\n",
    "encoder.save('encoder_25epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I know that I'm gay if I never had sex? 0.99999994\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "def most_similar(s):\n",
    "    v = encoder.predict(get_features_from_list_docs(nlp.pipe([s]), max_length=maxlen))[0]\n",
    "    sims = np.dot(valid_vec, v)\n",
    "    for i in sims.argsort()[-10:][::-1]:\n",
    "        if sims[i] > 0.66:\n",
    "            print(valid_data.iloc[i][1],sims[i])\n",
    "    print(\"=============================\")\n",
    "\n",
    "# most_similar(u'What is the concept of Cisco GPL 2016?')\n",
    "# most_similar(u'What are the best Web Hosting discount deals for New Year 2017?')\n",
    "most_similar(u'How can I know that I\\'m gay if I never had sex?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the best way to prepare for TCS Aptitude Test? 1.0\n",
      "How do I crack the TCS aptitude test? 0.7359774\n",
      "=============================\n",
      "What does it really mean to be married? 0.99999994\n",
      "What does it mean to be married? 0.96669066\n",
      "=============================\n",
      "What is a statement sentence? What are some examples? 0.9999999\n",
      "What are statement sentences? What are some examples? 0.7649162\n",
      "=============================\n",
      "What should my rank be in JEE Main to get CSE in IIITD if I'm OBC of outside Delhi region? 1.0\n",
      "What should my rank be in JEE Main to get CSE in IIITD if I'm OBC of Delhi region? 0.9444523\n",
      "=============================\n",
      "How are table salt and cooking salt different? 0.99999994\n",
      "How does table salt differ from cooking salt? 0.7755568\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "for s in valid_data.sample(n=5).question.values:\n",
    "    most_similar(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
